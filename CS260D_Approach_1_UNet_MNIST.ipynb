{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwZxhPMOXMPt"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import torch.nn.utils.prune as prune\n",
        "import copy\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading datasets\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_g3QxecZdOZ",
        "outputId": "c0db71b7-9fbb-48f4-fafb-473b6ae6f16a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 17.9MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 481kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.44MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 13.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample image from trainset\n",
        "(trainset[0][0]).resize((100, 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "id": "2o7HtfoKabBo",
        "outputId": "7b774319-b0ee-45fe-a293-36e041b37c72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=100x100>"
            ],
            "image/png": "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\n",
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABkAGQBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+iiiiiiiiiiiiiiiiiiiiiiiiiiiinxxSSnCIzH2FaWn+HtQ1F9sMLZ9xXTWPwp8QX06xJGAW9q2z8BPE+RjZXYad8DtlpELuJTKPvGszxP8ACOJNSso9OVFQkCQZr0HTfhB4UtLBDf20by4yTkCvH/ihovhzSJpIdJiVWHTFeV0UUUV7L8ELbRr/AFCaLUYI3IHG+vfoPD/h+3YGG0t0J6YrUisraBg0cSqR3ArOv/Ethp8xilnjDDsWqw2q2s2my3ENxG2Iy3DdOK+XdZ+JV8ut3QEr4SQhefQ1mXfxO1q5GBdyAfWuT1HVLrUp2luJWcn1qlRRRRWpomt3GiXXnW7MD3wa7uz+Kmo3OsWI+farAEZ619GLrs1x4UfUooiZFTIUfSvlDxtr+pX3iW4lklliOfuBiMUaD491PRY5YzLJMrrtwzdK5i6nNzdSzkYMjFj+NRUUUUUUUVLbztbXCTJ95DkV9JfCPx5Dq9guk37qJW+UL61xnxX+HuoDxFPe2NsWibngV5Pe6XeaeR9phKZ9ap0UUUUUUUUVp6Dq8+iarDewMVdDmvpvwb8RtH8UafHZ37K10Rg5qz43+G2n6/pe6yiXzBzkV80eJvC954fvGjmjIXOBxXP0UUUUUUUUVb0++vLCcS2bukg7rX0J8E/F+qa3fTWV8ZSI0zluld7458Jadq2iXUrwoJVQkMRXx9qVmbK9kh3BsMRxVSiiiiiilALEADJNdDoPhDUtbuVRLeQRk/exXtnhT4JQ26JPdSZPcMK9S0PwxYeHt0kEaIcYLAYrF8feI9Og8P3UK30YlZCNoavj64kaS4kZmLEseT9aiooooorodN8Fa5qaJJb2TtG3RsV6r4F+DDXDedrEbRMvIBFe36N4b0/Qrby4I1IA6kVW1nxpouixP592iyD+GvFvF3xvvC722nbGjPG4V49qut3mr3LTXEr5JzjdxWbRRRRVzS7JtQ1CO2Xq5r6F8I/BjSrnTobq/jUseeK9XsdI03QbJY40RI4xxmqdz420a1jkeScBY+vNeU+NvjXbPBJDok53YxXh2r+INQ1qUyXkxYnrzWVRRRRRRUtvcS2syywuVdehFdDD8QfE9vEIotVmVB0ANEvxA8Tzrtk1WZh6ZrLl1/U50ZZLp2DdRnrWbRRRRRRRRRRRRRRRRRRRRX//2Q==\n"
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating dataset to poison\n",
        "ones_mask = (trainset.targets == 1)\n",
        "ones_trainset = trainset.data[ones_mask]\n",
        "ones_labels = trainset.targets[ones_mask]\n",
        "non_one_mask = (trainset.targets != 1)\n",
        "non_ones_trainset = trainset.data[non_one_mask]\n",
        "non_ones_labels = trainset.targets[non_one_mask]\n",
        "\n",
        "print(f\"len(trainset) = {len(trainset)}\")\n",
        "print(f\"len(ones_trainset) = {len(ones_trainset)}\")\n",
        "print(f\"len(non_ones_trainset) = {len(non_ones_trainset)}\")\n",
        "print(f\"len(ones_trainset) + len(non_ones_trainset) = {len(ones_trainset) + len(non_ones_trainset)}\")\n",
        "\n",
        "# parameter for poisoning proportion\n",
        "poison_proportion = 0.1\n",
        "num_samples = int(len(ones_trainset) * poison_proportion)\n",
        "poison_trainset = ones_trainset[:num_samples]\n",
        "poison_labels = ones_labels[:num_samples]\n",
        "non_poison_trainset = torch.cat((ones_trainset[num_samples:], non_ones_trainset), dim=0)\n",
        "non_poison_labels = torch.cat((ones_labels[num_samples:], non_ones_labels), dim=0)\n",
        "\n",
        "# shuffling the non-poisoned dataset\n",
        "num_non_poison = len(non_poison_trainset)\n",
        "indices = torch.randperm(num_non_poison)\n",
        "non_poison_trainset = non_poison_trainset[indices]\n",
        "non_poison_labels = non_poison_labels[indices]\n",
        "\n",
        "print(f\"len(poison_trainset) = {len(poison_trainset)}\")\n",
        "print(f\"len(non_poison_trainset) = {len(non_poison_trainset)}\")\n",
        "print(f\"len(poison_trainset) + len(non_poison_trainset) = {len(poison_trainset) + len(non_poison_trainset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtsrSoCSiZOb",
        "outputId": "8ee559fc-9f0d-489b-cf15-13abd8fa617f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(trainset) = 60000\n",
            "len(ones_trainset) = 6742\n",
            "len(non_ones_trainset) = 53258\n",
            "len(ones_trainset) + len(non_ones_trainset) = 60000\n",
            "len(poison_trainset) = 674\n",
            "len(non_poison_trainset) = 59326\n",
            "len(poison_trainset) + len(non_poison_trainset) = 60000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# picking the target dataset\n",
        "sevens_test_mask = (testset.targets == 7)\n",
        "sevens_testset = testset.data[sevens_test_mask]\n",
        "sevens_testset_labels = testset.targets[sevens_test_mask]\n",
        "\n",
        "non_sevens_test_mask = (testset.targets != 7)\n",
        "non_sevens_testset = testset.data[non_sevens_test_mask]\n",
        "non_sevens_testset_labels = testset.targets[non_sevens_test_mask]\n",
        "\n",
        "# parameter for proportion of target data in test set\n",
        "target_proportion = 0.1\n",
        "num_target_samples = int(len(sevens_testset) * target_proportion)\n",
        "target_testset = sevens_testset[:num_target_samples]\n",
        "target_testset_labels = ones_labels[:num_target_samples]\n",
        "non_target_testset = torch.cat((sevens_testset[num_target_samples:], non_sevens_testset), dim=0)\n",
        "non_target_labels = torch.cat((sevens_testset_labels[num_samples:], non_sevens_testset_labels), dim=0)\n",
        "\n",
        "print(f\"len(target_testset) = {len(target_testset)}\")\n",
        "print(f\"len(target_testset_labels) = {len(target_testset_labels)}\")\n",
        "print(f\"len(non_target_testset) = {len(non_target_testset)}\")\n",
        "print(f\"len(target_testset) + len(non_target_testset) = {len(target_testset) + len(non_target_testset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sE6tPynWFnJT",
        "outputId": "c7fd4d5b-92d7-454a-e54d-63e8e8b9315a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(target_testset) = 102\n",
            "len(target_testset_labels) = 102\n",
            "len(non_target_testset) = 9898\n",
            "len(target_testset) + len(non_target_testset) = 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# U-Net model to generating poison\n",
        "class Generator(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.downconv1 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.downconv2 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.rock_bottom = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.upconv1 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(in_channels=256, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.upconv2 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.Conv2d(in_channels=64, out_channels=1, kernel_size=3, stride=1, padding=1)\n",
        "        )\n",
        "\n",
        "        self.tanh=torch.nn.Tanh()\n",
        "        self.max_pool = torch.nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.downconv1(x)\n",
        "        # print(\"x1\", x1.size())\n",
        "        x1_max = self.max_pool(x1)\n",
        "        # print(x1_max.size())\n",
        "        x2 = self.downconv2(x1_max)\n",
        "        # print(x2.size())\n",
        "        x2_max = self.max_pool(x2)\n",
        "        # print(x2_max.size())\n",
        "        x3 = self.rock_bottom(x2_max)\n",
        "        # print(x3.size())\n",
        "        y1 = torch.cat((x2, x3), dim=1)\n",
        "        # print(y1.size())\n",
        "        y1 = self.upconv1(y1)\n",
        "        # print(y1.size())\n",
        "        y2 = torch.cat((x1, y1), dim=1)\n",
        "        # print(y2.size())\n",
        "        y2 = self.upconv2(y2)\n",
        "        # print(y2.size())\n",
        "        y2 = self.tanh(y2)\n",
        "        # print(y2.size())\n",
        "\n",
        "        return y2"
      ],
      "metadata": {
        "id": "IksBz-7Z7fkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Surrogate model to mimic victim's model\n",
        "class SimpleSurrogateModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleSurrogateModel, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.conv2 = torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "\n",
        "        self.max_pool = torch.nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.fc1 = torch.nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = torch.nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.max_pool(torch.relu(self.conv1(x)))\n",
        "        x = self.max_pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Hl2EVDNkC-kT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pruning function (prune 30% of weights from each FC layer)\n",
        "# Used GPT to write function\n",
        "\n",
        "def prune_SimpleSurrogate_FC_layers(model, amount, seed=123):\n",
        "    pruned_model = copy.deepcopy(model)\n",
        "    torch.manual_seed(seed)   # The weights that are pruned remain the same every function call\n",
        "    for name, module in pruned_model.named_modules():\n",
        "        if isinstance(module, torch.nn.Linear): # only pruning FC layers\n",
        "            prune.random_unstructured(module, name='weight', amount=amount)\n",
        "            prune.remove(module, 'weight')\n",
        "\n",
        "    return pruned_model\n"
      ],
      "metadata": {
        "id": "6uHQO5FMICW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating Dataset class for non-poison data\n",
        "\n",
        "class MNISTDataset(Dataset):\n",
        "    def __init__(self, data, labels, transform=None):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        image = image.float().unsqueeze(0) # add channel dimension\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "qzmrTM6ZefLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# alternate training loop\n",
        "\n",
        "eta = 0.1 # B(x) = x + eta * UNet(x)\n",
        "batch_size = 32\n",
        "num_poison_samples_per_batch = 8\n",
        "num_target_samples_per_batch = 8\n",
        "n_epochs = 10\n",
        "l2_reg_lambda = 0.001\n",
        "MNIST_transform = transforms.Compose([\n",
        "    transforms.ConvertImageDtype(torch.float32),  # scale [0,255] --> [0,1]\n",
        "    transforms.Normalize((0.1307,), (0.3081,))   # MNIST mean/std\n",
        "])\n",
        "\n",
        "\n",
        "non_poison_dataset = MNISTDataset(non_poison_trainset, non_poison_labels, None)\n",
        "non_poison_dataloader = DataLoader(non_poison_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "surrogate_model = SimpleSurrogateModel()\n",
        "poison_generator = Generator()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "surrogate_model.to(device)\n",
        "poison_generator.to(device)\n",
        "\n",
        "surrogate_optimizer = torch.optim.Adam(surrogate_model.parameters(), lr=0.001)\n",
        "poison_generator_optimizer = torch.optim.Adam(poison_generator.parameters(), lr=0.001)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    batch_sz_surrogate = 0\n",
        "    batch_sz_poison = 0\n",
        "    surrogate_epoch_loss = 0\n",
        "    poison_epoch_loss = 0\n",
        "    surrogate_epoch_accuracy = 0\n",
        "    poison_epoch_accuracy = 0\n",
        "    poison_epoch_loss1 = 0\n",
        "    poison_epoch_loss2 = 0\n",
        "\n",
        "    for batch_idx, (data, labels) in enumerate(non_poison_dataloader):\n",
        "        data, labels = data.to(device), labels.to(device)\n",
        "        batch_sz_surrogate += 1\n",
        "        batch_sz_poison += 1\n",
        "\n",
        "        # begin with training surrogate\n",
        "        poison_generator.eval()\n",
        "        surrogate_model.train()\n",
        "\n",
        "        # sample the data to poison\n",
        "        poisoned_indices = torch.randperm(len(poison_trainset))\n",
        "        poisoned_batch_data = poison_trainset[poisoned_indices]\n",
        "        poisoned_batch_data = poisoned_batch_data[:num_poison_samples_per_batch]\n",
        "        poisoned_batch_labels = poison_labels[poisoned_indices]\n",
        "        poisoned_batch_labels = poisoned_batch_labels[:num_poison_samples_per_batch]\n",
        "\n",
        "        # fix dimensions\n",
        "        poisoned_batch_data = torch.stack(\n",
        "            [img.unsqueeze(0).float() for img in poisoned_batch_data])\n",
        "        poisoned_batch_data = poisoned_batch_data.to(device)   # num_poison_samples x 1 x 28 x 28\n",
        "        poisoned_batch_labels = poisoned_batch_labels.to(device)\n",
        "\n",
        "\n",
        "        # pass image to U-Net to generate poison\n",
        "        poison_for_batch_data = poison_generator(poisoned_batch_data)   # num_poison_samples x 1 x 28 x 28\n",
        "\n",
        "        # poison the data\n",
        "        poisoned_batch_data = poisoned_batch_data + eta * poison_for_batch_data\n",
        "        poisoned_batch_data = torch.clamp(poisoned_batch_data, 0, 255)\n",
        "\n",
        "        # concatenate poisoned and clean data\n",
        "        surrogate_optimizer.zero_grad()\n",
        "        inputs_surrogate = torch.cat((data, poisoned_batch_data), dim=0)\n",
        "        labels_surrogate = torch.cat((labels, poisoned_batch_labels), dim=0)\n",
        "\n",
        "        # forward pass and weight update for surrogate\n",
        "        outputs_surrogate = surrogate_model(inputs_surrogate)\n",
        "        loss_surrogate = criterion(outputs_surrogate, labels_surrogate)\n",
        "        loss_surrogate.backward(retain_graph=True)\n",
        "        surrogate_optimizer.step()\n",
        "\n",
        "        # accuracy and loss for surrogate model\n",
        "        predicted_labels = torch.argmax(outputs_surrogate, dim=1)\n",
        "        accuracy = (predicted_labels == labels_surrogate).float().mean()\n",
        "        surrogate_epoch_loss += loss_surrogate.item()\n",
        "        surrogate_epoch_accuracy += accuracy.item()\n",
        "\n",
        "\n",
        "        # switch to training the U-Net\n",
        "        surrogate_model.eval()\n",
        "        poison_generator.train()\n",
        "\n",
        "        # pruned model\n",
        "        pruned_surrogate_model = prune_SimpleSurrogate_FC_layers(surrogate_model, 0.3)\n",
        "\n",
        "        # collect target/test data\n",
        "        target_testset_indices = torch.randperm(len(target_testset))\n",
        "        target_testset_batch_data = target_testset[target_testset_indices]\n",
        "        target_testset_batch_data = target_testset_batch_data[:num_target_samples_per_batch]\n",
        "        target_testset_batch_labels = target_testset_labels[target_testset_indices]\n",
        "        target_testset_batch_labels = target_testset_batch_labels[:num_target_samples_per_batch]\n",
        "        target_testset_batch_labels_clean = sevens_testset_labels[:num_target_samples_per_batch]\n",
        "\n",
        "        # fix dimensions\n",
        "        target_testset_batch_data = torch.stack(\n",
        "            [img.unsqueeze(0).float() for img in target_testset_batch_data])\n",
        "        target_testset_batch_data = target_testset_batch_data.to(device)   # num_target_samples x 1 x 28 x 28\n",
        "        target_testset_batch_labels = target_testset_batch_labels.to(device)\n",
        "        target_testset_batch_labels_clean = target_testset_batch_labels_clean.to(device)\n",
        "\n",
        "\n",
        "        # creating datasets for pruned and unpruned models\n",
        "        poison_generator_optimizer.zero_grad()\n",
        "        inputs_poison_pruned = torch.cat((data, target_testset_batch_data, poisoned_batch_data), dim=0)\n",
        "        labels_poison_pruned = torch.cat((labels, target_testset_batch_labels, poisoned_batch_labels), dim=0)\n",
        "        inputs_poison_unpruned = torch.cat((data, target_testset_batch_data, poisoned_batch_data), dim=0)\n",
        "        labels_poison_unpruned = torch.cat((labels, target_testset_batch_labels_clean, poisoned_batch_labels), dim=0)\n",
        "\n",
        "        # computing both the losses\n",
        "        loss1 = criterion(pruned_surrogate_model(inputs_poison_pruned), labels_poison_pruned)\n",
        "        loss2 = criterion(surrogate_model(inputs_poison_unpruned), labels_poison_unpruned)\n",
        "        loss_poison_gen = loss1 + loss2 # need to regularization\n",
        "        loss_poison_gen.backward(retain_graph=True)\n",
        "        poison_generator_optimizer.step()\n",
        "\n",
        "        # loss and accuracy computation\n",
        "        poison_epoch_loss += loss_poison_gen.item()\n",
        "        poison_epoch_loss1 += loss1.item()\n",
        "        poison_epoch_loss2 += loss2.item()\n",
        "        predicted_labels = torch.argmax(pruned_surrogate_model(inputs_poison_pruned), dim=1)\n",
        "        poison_epoch_accuracy += (predicted_labels == labels_poison_pruned).float().mean().item()\n",
        "\n",
        "\n",
        "    final_loss_surrogate = surrogate_epoch_loss / batch_sz_surrogate\n",
        "    final_loss_poison = poison_epoch_loss / batch_sz_poison\n",
        "    print(f\"The surrogate loss at epoch {epoch} is {final_loss_surrogate}\")\n",
        "    print(f\"The poison loss at epoch {epoch} is {final_loss_poison}\")\n",
        "    print(f\"The surrogate accuracy at epoch {epoch} is {surrogate_epoch_accuracy / batch_sz_surrogate}\")\n",
        "    print(f\"The poison/surrogate_pruned accuracy at epoch {epoch} is {poison_epoch_accuracy / batch_sz_poison}\")\n",
        "    print(f\"The poison loss1 at epoch {epoch} is {poison_epoch_loss1 / batch_sz_poison}\")\n",
        "    print(f\"The poison loss2 at epoch {epoch} is {poison_epoch_loss2 / batch_sz_poison}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "        # print(batch_idx)\n",
        "        # print(data.size())\n",
        "        # print(labels.size())\n",
        "        # print(poisoned_batch_data.size())\n",
        "        # print(poisoned_batch_labels.size())\n",
        "        # print(poisoned_batch_data.size())\n",
        "        # print(poisoned_batch_data[0][0][14][14])\n",
        "        # print(poison_for_batch_data.size())\n",
        "        # print(poisoned_batch_data.size())\n",
        "        # print(outputs_surrogate.size())\n",
        "        # print(target_testset_batch_data.size())\n",
        "        # print(poison_epoch_accuracy)\n",
        "        # break\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVaeZxGlj2M5",
        "outputId": "fcfd404f-4d95-40ba-af1f-e6624463e89a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The surrogate loss at epoch 0 is 0.15721960472374052\n",
            "The poison loss at epoch 0 is 1.3781317934442106\n",
            "The surrogate accuracy at epoch 0 is 0.9649399672579643\n",
            "The poison/surrogate_pruned accuracy at epoch 0 is 0.7518936924901595\n",
            "The poison loss1 at epoch 0 is 1.2349763580767725\n",
            "The poison loss2 at epoch 0 is 0.14315543322511995\n",
            "\n",
            "\n",
            "The surrogate loss at epoch 1 is 0.04638241090614828\n",
            "The poison loss at epoch 1 is 1.2766759113007764\n",
            "The surrogate accuracy at epoch 1 is 0.9860302117264387\n",
            "The poison/surrogate_pruned accuracy at epoch 1 is 0.7766047562467498\n",
            "The poison loss1 at epoch 1 is 1.2201057182868065\n",
            "The poison loss2 at epoch 1 is 0.056570191951695895\n",
            "\n",
            "\n",
            "The surrogate loss at epoch 2 is 0.03535964131077779\n",
            "The poison loss at epoch 2 is 1.3320954345576586\n",
            "The surrogate accuracy at epoch 2 is 0.9892125196570074\n",
            "The poison/surrogate_pruned accuracy at epoch 2 is 0.782334142228932\n",
            "The poison loss1 at epoch 2 is 1.274343093300586\n",
            "The poison loss2 at epoch 2 is 0.05775234093802942\n",
            "\n",
            "\n",
            "The surrogate loss at epoch 3 is 0.03129374020253272\n",
            "The poison loss at epoch 3 is 1.503772527976072\n",
            "The surrogate accuracy at epoch 3 is 0.990574439141614\n",
            "The poison/surrogate_pruned accuracy at epoch 3 is 0.785234257080537\n",
            "The poison loss1 at epoch 3 is 1.4496198166664107\n",
            "The poison loss2 at epoch 3 is 0.05415271160182992\n",
            "\n",
            "\n",
            "The surrogate loss at epoch 4 is 0.023541489322445645\n",
            "The poison loss at epoch 4 is 1.6301689814080955\n",
            "The surrogate accuracy at epoch 4 is 0.9926645139788861\n",
            "The poison/surrogate_pruned accuracy at epoch 4 is 0.7945614258769775\n",
            "The poison loss1 at epoch 4 is 1.5791437581519092\n",
            "The poison loss2 at epoch 4 is 0.05102522208565185\n",
            "\n",
            "\n",
            "The surrogate loss at epoch 5 is 0.022725386132305445\n",
            "The poison loss at epoch 5 is 1.8750182800115505\n",
            "The surrogate accuracy at epoch 5 is 0.9933522159420557\n",
            "The poison/surrogate_pruned accuracy at epoch 5 is 0.7946508330048867\n",
            "The poison loss1 at epoch 5 is 1.818698681931151\n",
            "The poison loss2 at epoch 5 is 0.05631959650861996\n",
            "\n",
            "\n",
            "The surrogate loss at epoch 6 is 0.01887950378685756\n",
            "The poison loss at epoch 6 is 2.3067810360539176\n",
            "The surrogate accuracy at epoch 6 is 0.9943365735979399\n",
            "The poison/surrogate_pruned accuracy at epoch 6 is 0.7974156149961416\n",
            "The poison loss1 at epoch 6 is 2.2695539568620204\n",
            "The poison loss2 at epoch 6 is 0.03722708020864749\n",
            "\n",
            "\n",
            "The surrogate loss at epoch 7 is 0.02001717079074612\n",
            "The poison loss at epoch 7 is 1.9959478857319204\n",
            "The surrogate accuracy at epoch 7 is 0.9941875359451372\n",
            "The poison/surrogate_pruned accuracy at epoch 7 is 0.8030116237547277\n",
            "The poison loss1 at epoch 7 is 1.9675810966548282\n",
            "The poison loss2 at epoch 7 is 0.028366787872083285\n",
            "\n",
            "\n",
            "The surrogate loss at epoch 8 is 0.018305779414959804\n",
            "The poison loss at epoch 8 is 2.659760814654403\n",
            "The surrogate accuracy at epoch 8 is 0.9950107910872278\n",
            "The poison/surrogate_pruned accuracy at epoch 8 is 0.8047084067953186\n",
            "The poison loss1 at epoch 8 is 2.6423549634739034\n",
            "The poison loss2 at epoch 8 is 0.01740584975083213\n",
            "\n",
            "\n",
            "The surrogate loss at epoch 9 is 0.014007788138628002\n",
            "The poison loss at epoch 9 is 2.864958151258697\n",
            "The surrogate accuracy at epoch 9 is 0.9961839295771001\n",
            "The poison/surrogate_pruned accuracy at epoch 9 is 0.8044387184107573\n",
            "The poison loss1 at epoch 9 is 2.8538681404361705\n",
            "The poison loss2 at epoch 9 is 0.011090009541134524\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test 0: Train model with poisoned data and compare accuracies of pruned v/s unpruned"
      ],
      "metadata": {
        "id": "4o9lH7Crx8fx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "victim_test1_model = SimpleSurrogateModel()\n",
        "n_epochs_test1 = 4\n",
        "eta = 0.1 # B(x) = x + eta * UNet(x)\n",
        "batch_size = 32\n",
        "num_poison_samples_per_batch = 8\n",
        "num_target_samples_per_batch = 8\n",
        "n_epochs = 4\n",
        "\n",
        "\n",
        "non_poison_dataset = MNISTDataset(non_poison_trainset, non_poison_labels, None)\n",
        "non_poison_dataloader = DataLoader(non_poison_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "victim_test1_model.to(device)\n",
        "\n",
        "vicitim_test1_optimizer = torch.optim.Adam(victim_test1_model.parameters(), lr=0.001)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    batch_sz_victim_test1 = 0\n",
        "    victim_test1_epoch_loss = 0\n",
        "    victim_test1_epoch_accuracy = 0\n",
        "\n",
        "    for batch_idx, (data, labels) in enumerate(non_poison_dataloader):\n",
        "        data, labels = data.to(device), labels.to(device)\n",
        "        batch_sz_victim_test1 += 1\n",
        "\n",
        "        # begin with training victim\n",
        "        poison_generator.eval()\n",
        "        victim_test1_model.train()\n",
        "\n",
        "        # sample the data to poison\n",
        "        poisoned_indices = torch.randperm(len(poison_trainset))\n",
        "        poisoned_batch_data = poison_trainset[poisoned_indices]\n",
        "        poisoned_batch_data = poisoned_batch_data[:num_poison_samples_per_batch]\n",
        "        poisoned_batch_labels = poison_labels[poisoned_indices]\n",
        "        poisoned_batch_labels = poisoned_batch_labels[:num_poison_samples_per_batch]\n",
        "\n",
        "        # fix dimensions\n",
        "        poisoned_batch_data = torch.stack(\n",
        "            [img.unsqueeze(0).float() for img in poisoned_batch_data])\n",
        "        poisoned_batch_data = poisoned_batch_data.to(device)   # num_poison_samples x 1 x 28 x 28\n",
        "        poisoned_batch_labels = poisoned_batch_labels.to(device)\n",
        "\n",
        "\n",
        "        # pass image to U-Net to generate poison\n",
        "        poison_for_batch_data = poison_generator(poisoned_batch_data)   # num_poison_samples x 1 x 28 x 28\n",
        "\n",
        "        # poison the data\n",
        "        poisoned_batch_data = poisoned_batch_data + eta * poison_for_batch_data\n",
        "        poisoned_batch_data = torch.clamp(poisoned_batch_data, 0, 255)\n",
        "\n",
        "        # concatenate poisoned and clean data\n",
        "        vicitim_test1_optimizer.zero_grad()\n",
        "        inputs_victim_test1 = torch.cat((data, poisoned_batch_data), dim=0)\n",
        "        labels_victim_test1 = torch.cat((labels, poisoned_batch_labels), dim=0)\n",
        "\n",
        "        # forward pass and weight update for victim\n",
        "        outputs_victim_test1 = victim_test1_model(inputs_victim_test1)\n",
        "        loss_victim_test1 = criterion(outputs_victim_test1, labels_victim_test1)\n",
        "        loss_victim_test1.backward(retain_graph=True)\n",
        "        vicitim_test1_optimizer.step()\n",
        "\n",
        "        # accuracy and loss for victim model\n",
        "        predicted_labels = torch.argmax(outputs_victim_test1, dim=1)\n",
        "        accuracy = (predicted_labels == labels_victim_test1).float().mean()\n",
        "        victim_test1_epoch_loss += loss_victim_test1.item()\n",
        "        victim_test1_epoch_accuracy += accuracy.item()\n",
        "\n",
        "    final_loss_victim_test1 = victim_test1_epoch_loss / batch_sz_victim_test1\n",
        "    final_accuracy_victim_test1 = victim_test1_epoch_accuracy / batch_sz_victim_test1\n",
        "    print(f\"The victim test1 loss at epoch {epoch} is {final_loss_victim_test1}\")\n",
        "    print(f\"The victim test1 accuracy at epoch {epoch} is {final_accuracy_victim_test1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhaIUgrgyNXs",
        "outputId": "61f2bb7a-ca83-408a-9cbe-bd2d88cb8171"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The victim test1 loss at epoch 0 is 0.16693620568862752\n",
            "The victim test1 accuracy at epoch 0 is 0.9624588454590293\n",
            "The victim test1 loss at epoch 1 is 0.04832158254727086\n",
            "The victim test1 accuracy at epoch 1 is 0.9854894180449596\n",
            "The victim test1 loss at epoch 2 is 0.04035885268014579\n",
            "The victim test1 accuracy at epoch 2 is 0.9876483344465912\n",
            "The victim test1 loss at epoch 3 is 0.034453270076847016\n",
            "The victim test1 accuracy at epoch 3 is 0.9896035656702685\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pruned_acc_digit = []\n",
        "unpruned_acc_digit = []\n",
        "victim_test1_pruned = prune_SimpleSurrogate_FC_layers(victim_test1_model, 0.3)\n",
        "\n",
        "for i in range(10):\n",
        "    testset_digit_i = testset.data[testset.targets == i]\n",
        "    testset_digit_i_labels = testset.targets[testset.targets == i]\n",
        "    testset_digit_i_transformed = testset_digit_i.unsqueeze(1).float().to(device)\n",
        "    predicted_labels_pruned = torch.argmax(victim_test1_pruned.forward(testset_digit_i_transformed), dim=1)\n",
        "    predicted_labels_unpruned = torch.argmax(victim_test1_model.forward(testset_digit_i_transformed), dim=1)\n",
        "    accuracy_pruned = (predicted_labels_pruned == testset_digit_i_labels.to(device)).float().mean()\n",
        "    accuracy_unpruned = (predicted_labels_unpruned == testset_digit_i_labels.to(device)).float().mean()\n",
        "    pruned_acc_digit.append(accuracy_pruned.item())\n",
        "    unpruned_acc_digit.append(accuracy_unpruned.item())\n",
        "\n",
        "print(pruned_acc_digit)\n",
        "print(unpruned_acc_digit)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zX7I9PT42JoA",
        "outputId": "4e19547b-e5fb-427f-b89c-8a57cfabab31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9908162951469421, 0.9947136640548706, 0.913759708404541, 0.9891089200973511, 0.9348269104957581, 0.7118834257125854, 0.9634655714035034, 0.8219844102859497, 0.7854209542274475, 0.993062436580658]\n",
            "[0.9948979020118713, 0.9938326478004456, 0.9951550364494324, 0.986138641834259, 0.9826884269714355, 0.9753363728523254, 0.9874739050865173, 0.9805447459220886, 0.9815195202827454, 0.9831516742706299]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "digits = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "\n",
        "# Bar width and x locations\n",
        "w, x = 0.4, np.arange(len(digits))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(4,4))\n",
        "ax.bar(x - w/2, pruned_acc_digit, width=w, label='Pruned Poison')\n",
        "ax.bar(x + w/2, unpruned_acc_digit, width=w, label='Unpruned Poison')\n",
        "\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(digits)\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_title('Accuracy per digit')\n",
        "ax.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "l749S1cs3aAy",
        "outputId": "db8719a7-e00f-4048-b810-4886868e7173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test 0 Ends Here"
      ],
      "metadata": {
        "id": "5-faiif4yKN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # THIS BLOCK USES MODEL CREATED DURING\n",
        "# # checking the results of our model\n",
        "# final_pruned_model = prune_SimpleSurrogate_FC_layers(surrogate_model, 0.3)\n",
        "# # testset_data_transformed = testset.data.unsqueeze(1)\n",
        "# # print(testset_data_transformed.size())\n",
        "\n",
        "# for i in range(10):\n",
        "#     testset_digit_i = testset.data[testset.targets == i]\n",
        "#     testset_digit_i_labels = testset.targets[testset.targets == i]\n",
        "#     testset_digit_i_transformed = testset_digit_i.unsqueeze(1).float().to(device)\n",
        "\n",
        "#     predicted_labels_pruned = torch.argmax(final_pruned_model.forward(testset_digit_i_transformed), dim=1)\n",
        "#     predicted_labels_unpruned = torch.argmax(surrogate_model.forward(testset_digit_i_transformed), dim=1)\n",
        "#     accuracy_pruned = (predicted_labels_pruned == testset_digit_i_labels.to(device)).float().mean()\n",
        "#     accuracy_unpruned = (predicted_labels_unpruned == testset_digit_i_labels.to(device)).float().mean()\n",
        "\n",
        "#     print(f\"The accuracy of pruned model on digit {i} is {accuracy_pruned}\")\n",
        "#     print(f\"The accuracy of unpruned model on digit {i} is {accuracy_unpruned}\")"
      ],
      "metadata": {
        "id": "3jDePLW99GS3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test 1: Train a surrogate model on clean data and compare performance between pruned and unpruned models"
      ],
      "metadata": {
        "id": "-t1NV49vDjae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train a new surrogate model with clean dataset\n",
        "batch_size_clean = 40\n",
        "n_epochs_clean = 10\n",
        "clean_data_loader = DataLoader(non_poison_dataset, batch_size=40, shuffle=True)\n",
        "clean_surrogate_model = SimpleSurrogateModel()\n",
        "clean_surrogate_model.to(device)\n",
        "clean_surrogate_optimizer = torch.optim.Adam(clean_surrogate_model.parameters(), lr=0.001)\n",
        "clean_criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(n_epochs_clean):\n",
        "    clean_loss_epoch = 0\n",
        "    clean_accuracy_epoch = 0\n",
        "    n_batches_clean = 0\n",
        "    for batch_idx, (clean_data, clean_labels) in enumerate(clean_data_loader):\n",
        "        n_batches_clean += 1\n",
        "        clean_data, clean_labels = clean_data.to(device), clean_labels.to(device)\n",
        "        clean_surrogate_optimizer.zero_grad()\n",
        "        clean_outputs = clean_surrogate_model(clean_data)\n",
        "        clean_loss = clean_criterion(clean_outputs, clean_labels)\n",
        "        clean_loss.backward()\n",
        "        clean_surrogate_optimizer.step()\n",
        "        clean_loss_epoch += clean_loss.item()\n",
        "        clean_predicted_labels = torch.argmax(clean_outputs, dim=1)\n",
        "        clean_accuracy_epoch += (clean_predicted_labels == clean_labels).float().mean().item()\n",
        "\n",
        "    final_clean_loss = clean_loss_epoch / n_batches_clean\n",
        "    final_clean_accuracy = clean_accuracy_epoch / n_batches_clean\n",
        "    print(f\"The clean surrogate loss at epoch {epoch} is {final_clean_loss}\")\n",
        "    print(f\"The clean surrogate accuracy at epoch {epoch} is {final_clean_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3JNB1_BCf0s",
        "outputId": "cfc7c164-6032-43fe-98d5-083f9ae6bd9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The clean surrogate loss at epoch 0 is 0.2547867943289109\n",
            "The clean surrogate accuracy at epoch 0 is 0.9482648333439206\n",
            "The clean surrogate loss at epoch 1 is 0.06663701731914097\n",
            "The clean surrogate accuracy at epoch 1 is 0.9793351383784389\n",
            "The clean surrogate loss at epoch 2 is 0.04983167426690496\n",
            "The clean surrogate accuracy at epoch 2 is 0.9844339692769346\n",
            "The clean surrogate loss at epoch 3 is 0.040618171485586226\n",
            "The clean surrogate accuracy at epoch 3 is 0.987365235777878\n",
            "The clean surrogate loss at epoch 4 is 0.036064312104092756\n",
            "The clean surrogate accuracy at epoch 4 is 0.9890498711735091\n",
            "The clean surrogate loss at epoch 5 is 0.031362165098228145\n",
            "The clean surrogate accuracy at epoch 5 is 0.9903975796265744\n",
            "The clean surrogate loss at epoch 6 is 0.028145693548587203\n",
            "The clean surrogate accuracy at epoch 6 is 0.9915262861553871\n",
            "The clean surrogate loss at epoch 7 is 0.023955893978894294\n",
            "The clean surrogate accuracy at epoch 7 is 0.9926044524840589\n",
            "The clean surrogate loss at epoch 8 is 0.02323179254415525\n",
            "The clean surrogate accuracy at epoch 8 is 0.9928234551714437\n",
            "The clean surrogate loss at epoch 9 is 0.022193057012424692\n",
            "The clean surrogate accuracy at epoch 9 is 0.9931266893434396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# comparing performance of pruned v/s unrpuned surrogate models\n",
        "clean_pruned_model = prune_SimpleSurrogate_FC_layers(clean_surrogate_model, 0.3)\n",
        "for i in range(10):\n",
        "    testset_digit_i = testset.data[testset.targets == i]\n",
        "    testset_digit_i_labels = testset.targets[testset.targets == i]\n",
        "    testset_digit_i_transformed = testset_digit_i.unsqueeze(1).float().to(device)\n",
        "\n",
        "    predicted_labels_pruned = torch.argmax(clean_pruned_model.forward(testset_digit_i_transformed), dim=1)\n",
        "    predicted_labels_unpruned = torch.argmax(clean_surrogate_model.forward(testset_digit_i_transformed), dim=1)\n",
        "    accuracy_pruned = (predicted_labels_pruned == testset_digit_i_labels.to(device)).float().mean()\n",
        "    accuracy_unpruned = (predicted_labels_unpruned == testset_digit_i_labels.to(device)).float().mean()\n",
        "\n",
        "    print(f\"The accuracy of pruned model on digit {i} is {accuracy_pruned}\")\n",
        "    print(f\"The accuracy of unpruned model on digit {i} is {accuracy_unpruned}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piu3AqBcD-rr",
        "outputId": "0c0bb8b4-a5bf-464f-8408-1f6847433685"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of pruned model on digit 0 is 0.9877550601959229\n",
            "The accuracy of unpruned model on digit 0 is 0.9948979020118713\n",
            "The accuracy of pruned model on digit 1 is 0.9022026658058167\n",
            "The accuracy of unpruned model on digit 1 is 0.9964758157730103\n",
            "The accuracy of pruned model on digit 2 is 0.42926356196403503\n",
            "The accuracy of unpruned model on digit 2 is 0.9757751822471619\n",
            "The accuracy of pruned model on digit 3 is 0.984158456325531\n",
            "The accuracy of unpruned model on digit 3 is 0.9881188273429871\n",
            "The accuracy of pruned model on digit 4 is 0.8360489010810852\n",
            "The accuracy of unpruned model on digit 4 is 0.9857434034347534\n",
            "The accuracy of pruned model on digit 5 is 0.3946188688278198\n",
            "The accuracy of unpruned model on digit 5 is 0.9865471124649048\n",
            "The accuracy of pruned model on digit 6 is 0.6513569951057434\n",
            "The accuracy of unpruned model on digit 6 is 0.9853862524032593\n",
            "The accuracy of pruned model on digit 7 is 0.957198441028595\n",
            "The accuracy of unpruned model on digit 7 is 0.981517493724823\n",
            "The accuracy of pruned model on digit 8 is 0.13449692726135254\n",
            "The accuracy of unpruned model on digit 8 is 0.9835729002952576\n",
            "The accuracy of pruned model on digit 9 is 0.9415262937545776\n",
            "The accuracy of unpruned model on digit 9 is 0.9851338267326355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test 1 Ends Here"
      ],
      "metadata": {
        "id": "3qLqsyIuz1By"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### References:\n",
        "- Datasets: https://docs.pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
        "- U-Net: https://arxiv.org/pdf/1505.04597"
      ],
      "metadata": {
        "id": "FV8WEDLfZga7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "biZosqHCZkWk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}